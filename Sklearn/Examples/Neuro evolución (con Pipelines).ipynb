{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geneticos en Python: DEAP\n",
    "\n",
    "### Instalación\n",
    "\n",
    "https://anaconda.org/conda-forge/deap\n",
    "\n",
    "### Ejemplo comentado\n",
    "\n",
    "#### Tipos\n",
    "\n",
    "En DEAP en lugar de proporcionar tipos predefinidos se proporciona una manera de generar nuestros propios tipos.\n",
    "\n",
    "El módulo **creator** permite crear nuestros problemas.\n",
    "\n",
    "```Python\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", numpy.ndarray, fitness=creator.FitnessMax)\n",
    "```\n",
    "\n",
    "Crea *FitnessMax* como un tipo de problema de maximización.\n",
    "\n",
    "Segun el valor de weights, el problema puede ser:\n",
    "- (1.0,) maximizar\n",
    "- (-1.0,) minimzar\n",
    "- (-1.0, 1.0) Multi (minimizar el primero y maximizar el segundo)\n",
    "\n",
    "Se esta creando un individuo, que está representado por un array de numpy y pertenece al problema de maximización.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inicialización\n",
    "\n",
    "Una vez que se crean los tipos hay que asignarles valores.\n",
    "\n",
    "El paquete **toolbox** contiene herramientas para hacer esto.\n",
    "\n",
    "```Python\n",
    "IND_SIZE = 10\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attribute\", random.random)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual,\n",
    "                 toolbox.attribute, n=IND_SIZE)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "```\n",
    "\n",
    "Este código crea *attribute* que es un float con valor random. Los individuos  (*individual*) son una lista de *attribute* de tamaño *IND_SIZE* y *population* es una lista de individuos.\n",
    "\n",
    "Con **toolbox.population()** crearía automáticamente una población y con **toolbox.individual()** un individuo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operadores \n",
    "\n",
    "Los operadores de evaluación, selección, mutación y cruce son funciones. El usuario puede implementarlas o usar las que se encuentran en el módulo **tools**\n",
    "\n",
    "```Python\n",
    "def evaluate(individual):\n",
    "    return sum(individual),\n",
    "\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.1)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "```\n",
    "\n",
    "##### Evaluación\n",
    "La función de evaluación debe devolver una tupla ya que la optimización mono-objetivo es un caso especial de la multi-objetivo.\n",
    "La función **evaluate** devuelve la tupla con la suma y None, pero devuelve una tupla.\n",
    "\n",
    "##### Mutación\n",
    "\n",
    "Las funciones de mutación solo mutan, si se quiere mantener el original hay que hacer una copia explicitamente y almacenarla.\n",
    "\n",
    "```Python\n",
    "mutant = toolbox.clone(ind1)\n",
    "ind2, = tools.mutGaussian(mutant, mu=0.0, sigma=0.2, indpb=0.2)\n",
    "del mutant.fitness.values\n",
    "```\n",
    "\n",
    "(Se borran los valores de fitness porque no pertenecen al individuo mutado, sino al individuo anterior)\n",
    "\n",
    "- mutGaussian() Aplica una mutación de media mu y desviación sigma. Espera valores float\n",
    "- mutFlipBit() Invierte valores con una determinada probabilidad, espera booleanos.\n",
    "\n",
    "##### Cruce \n",
    "\n",
    "Hay variedad de operadores, cada uno espera un determinado tipo de individuos.\n",
    "Las funciones de cruce solo cruzan, si se quiere mantener el original hay que hacer una copia explicitamente y almacenarla.\n",
    "\n",
    "```Python\n",
    "child1, child2 = [toolbox.clone(ind) for ind in (ind1, ind2)]\n",
    "tools.cxBlend(child1, child2, 0.5)\n",
    "del child1.fitness.values\n",
    "del child2.fitness.values\n",
    "```\n",
    "\n",
    "- cxBlend() Espera floats, recibe un alpha que regula que valores se cogen de cada individuo\n",
    "- cxOnePoint() Hasta un punto aleatorio es de un individuo y despues del otro.\n",
    "- cxTwoPoint()\n",
    "\n",
    "#### Selección\n",
    "\n",
    "Son funciones que reciben un contenedor de individuos y el número de individuos a seleccionar.\n",
    "Si un individuo se selecciona dos veces, no se copia, los dos individuos apuntan al mismo objeto. Y mutar el uno muta al otro también. Habría que clonarlos.\n",
    "\n",
    "```Python\n",
    "selected = toolbox.select(population, LAMBDA)\n",
    "offspring = [toolbox.clone(ind) for ind in selected]\n",
    "```\n",
    "\n",
    "- selTournament()\n",
    "- selBest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando Toolbox\n",
    "\n",
    "El **Toolbox** tiene dos métodos **register()** y **unregister()** que ponen y quitan herramientas del toolbox.\n",
    "\n",
    "En el toolbox se registran las operaciones de cruce, mutación, selección y evaluación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms\n",
    "\n",
    "Hay varias implementaciones de algoritmos evolutivos en el módulo **algorithms**, estos algoritmos usan los métodos registrados en el **Toolbox**\n",
    "\n",
    "- eaSimple El algoritmo genético simple de “Evolutionary Computation 1 : Basic Algorithms and Operators” capitulo 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de la documentación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from deap import algorithms\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", np.ndarray, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=100)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "def evalOneMax(individual):\n",
    "    return sum(individual),\n",
    "\n",
    "def cxTwoPointCopy(ind1, ind2):\n",
    "    \"\"\"Execute a two points crossover with copy on the input individuals. The\n",
    "    copy is required because the slicing in numpy returns a view of the data,\n",
    "    which leads to a self overwritting in the swap operation. It prevents\n",
    "    ::\n",
    "    \n",
    "        >>> import numpy\n",
    "        >>> a = np.array((1,2,3,4))\n",
    "        >>> b = np.array((5.6.7.8))\n",
    "        >>> a[1:3], b[1:3] = b[1:3], a[1:3]\n",
    "        >>> print(a)\n",
    "        [1 6 7 4]\n",
    "        >>> print(b)\n",
    "        [5 6 7 8]\n",
    "    \"\"\"\n",
    "    size = len(ind1)\n",
    "    cxpoint1 = random.randint(1, size)\n",
    "    cxpoint2 = random.randint(1, size - 1)\n",
    "    if cxpoint2 >= cxpoint1:\n",
    "        cxpoint2 += 1\n",
    "    else: # Swap the two cx points\n",
    "        cxpoint1, cxpoint2 = cxpoint2, cxpoint1\n",
    "\n",
    "    ind1[cxpoint1:cxpoint2], ind2[cxpoint1:cxpoint2] \\\n",
    "        = ind2[cxpoint1:cxpoint2].copy(), ind1[cxpoint1:cxpoint2].copy()\n",
    "        \n",
    "    return ind1, ind2\n",
    "    \n",
    "    \n",
    "toolbox.register(\"evaluate\", evalOneMax)\n",
    "toolbox.register(\"mate\", cxTwoPointCopy)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "def main():\n",
    "    random.seed(64)\n",
    "    \n",
    "    pop = toolbox.population(n=300)\n",
    "    \n",
    "    ''' aqui meteria la red inicial\n",
    "    guess_ind = creator.Individual(valores)\n",
    "    \n",
    "    pop.pop()\n",
    "    pop.insert(0, guess_ind) \n",
    "    '''\n",
    "    \n",
    "    # Numpy equality function (operators.eq) between two arrays returns the\n",
    "    # equality element wise, which raises an exception in the if similar()\n",
    "    # check of the hall of fame. Using a different equality function like\n",
    "    # numpy.array_equal or numpy.allclose solve this issue.\n",
    "    hof = tools.HallOfFame(1, similar=np.array_equal)\n",
    "    \n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"std\", np.std)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "    \n",
    "    algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=40, stats=stats,\n",
    "                        halloffame=hof)\n",
    "\n",
    "    return pop, stats, hof\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ejemplo propio\n",
    "\n",
    "Encontrar $x, y ,z$ que minimizan una función\n",
    "\n",
    "$f(x,y,z) = (x-2)^2 + (y-3)^2 + (z-5)^2$\n",
    "\n",
    "Los óptimos serían $x=2, y=3, z=5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "En la función de evaluación, se devuelve un tupla aunque solo se optimize un valor, por eso\n",
    "la coma despues del primer valor retornado\n",
    "'''\n",
    "def evalFunct(individual):\n",
    "    x,y,z = individual\n",
    "    return (x-2)**2 + (y-3)**2 + (z-5)**2,\n",
    "\n",
    "arr = np.array([2,3,5])\n",
    "evalFunct(arr)\n",
    "\n",
    "\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,)) # Minimiza\n",
    "creator.create(\"Individual\", np.ndarray, fitness=creator.FitnessMin)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# se registra attr_int como un entero aleatorio entre 0 y 10\n",
    "# se registra individual como una repetición de attr_int de tamaño 3, el contenedor es el tipo Individual\n",
    "# se registra population como una repetición de individual, el contenedor es una lista\n",
    "toolbox.register(\"attr_int\", random.randint, 0, 10)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_int, n=3)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", evalFunct)\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0.0, sigma=0.2, indpb=0.2)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "\n",
    "random.seed(64)\n",
    "\n",
    "# se crea una población inicial de 50\n",
    "pop = toolbox.population(n=50)    \n",
    "    \n",
    "'''\n",
    "HallOfFame contiene los N mejores individuos vistos durante todo el proceso\n",
    "Como el tipo del individuo es personalizado hay que pasarle una función de comparación\n",
    "'''    \n",
    "hof = tools.HallOfFame(1, similar=np.array_equal)\n",
    "    \n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"std\", np.std)\n",
    "stats.register(\"min\", np.min)\n",
    "stats.register(\"max\", np.max)\n",
    "    \n",
    "pop, logbook = algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=10, stats=stats, halloffame=hof)\n",
    "print(hof)  \n",
    "hof[0] # esta ordenado de manera que el primer elemento es el mejor de siempre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mismo ejemplo pero con un *initial_guess* inicializo la población con algunos individuos que no son aleatorios\n",
    "http://deap.readthedocs.io/en/master/tutorials/basic/part1.html#seeding-a-population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def initPopulation(pop, ind_random, ind_guess,n_guess=1,n=10):\n",
    "    \n",
    "    pop = []\n",
    "    n_random = n - n_guess\n",
    "    for i in range(n_random):\n",
    "        pop.append(ind_random())\n",
    "        \n",
    "    for i in range(n_guess):\n",
    "        pop.append(ind_guess())\n",
    "    \n",
    "    return pop\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_int\", random.randint, 0, 10)\n",
    "toolbox.register(\"individual_rnd\", tools.initRepeat, creator.Individual, toolbox.attr_int, n=3)\n",
    "toolbox.register(\"individual_guess\", lambda :creator.Individual(np.array([3,4,5])))\n",
    "toolbox.register(\"population_mix\",initPopulation,list,toolbox.individual_rnd, toolbox.individual_guess)       \n",
    "\n",
    "# ejemplo para ver como se crea una población de 10, con 3 fijados por mi\n",
    "print(toolbox.population_mix(n=10, n_guess=3))\n",
    "\n",
    "toolbox.register(\"evaluate\", evalFunct)\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0.0, sigma=0.2, indpb=0.2)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "\n",
    "random.seed(64)\n",
    "\n",
    "# se crea una población de 50 con 10 fijos (he usado la función population_mix)\n",
    "pop = toolbox.population_mix(n=50, n_guess=10)      \n",
    "    \n",
    "'''\n",
    "HallOfFame contiene los N mejores individuos vistos durante todo el proceso\n",
    "Como el tipo del individuo es personalizado hay que pasarle una función de comparación\n",
    "'''    \n",
    "hof = tools.HallOfFame(1, similar=np.array_equal)\n",
    "    \n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"std\", np.std)\n",
    "stats.register(\"min\", np.min)\n",
    "stats.register(\"max\", np.max)\n",
    "    \n",
    "pop, logbook = algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=10, stats=stats, halloffame=hof)\n",
    "print(hof)  # ahora en lugar de converger en la generación 7, lo hace en la generación 4\n",
    "hof[0] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales con Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El MLPClassifier tiene varios solvers:\n",
    "- adam, un tipo de stochastic gradient descent para datos grandes\n",
    "- lbfgs para pequeños converge antes.\n",
    "\n",
    "solver : {‘lbfgs’, ‘sgd’, ‘adam’}, default ‘adam’\n",
    "\n",
    "\n",
    "Funciona para multilabel, pero no para multioutput, habría que modificar las clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = [[0., 0.], [1., 1.]]\n",
    "labels = [[0, 1], [1, 1]]\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(15,), random_state=1)\n",
    "\n",
    "clf.fit(train, labels)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**coefs\\_** es una lista de matrices donde la matriz *i* representa los pesos entre la capa *i* y la capa *i+1*\n",
    "\n",
    "**intercepts\\_** es un lista de vectores bias donde el vector *i* representa los bias añadidos a la capa *i+1*\n",
    "\n",
    "Nota: Por defecto 3 capas, entrada, capa oculta y capa de salida. Los coeficientes son de la entrada a la intermedia y de la intermedia a la salida. Los bias son de la intermedia y la de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[coef.shape for coef in clf.coefs_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "\n",
    "Uno de los consejos que se mencionan en la documentación de sklearn para el uso de las redes neuronales es la estandarización de los datos.\n",
    "http://scikit-learn.org/stable/modules/neural_networks_supervised.html#tips-on-practical-use\n",
    "\n",
    "Los perceptrones multicapa son sensibles a la escala de los datos y por lo tanto es recomendable *escalar* los datos. Para cada atributo es recomendable que sus valores se encuentren entre [0, 1] o [-1, +1] o estandardizar que significa que tengan media 0 y varianza 1 \n",
    "\n",
    "Se podría estandardizar haciendo lo siguiente:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "\n",
    "\n",
    "X_train, y = make_blobs(n_samples=10, centers=4,\n",
    "                  random_state=0, cluster_std=1.0)\n",
    "\n",
    "print(X_train,\" media \",np.mean(X_train,axis=0),\" std \",np.std(X_train,axis=0))\n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)  \n",
    "print(X_train,\" media \",np.mean(X_train,axis=0),\" std \",np.std(X_train,axis=0))\n",
    "\n",
    "# apply same transformation to test data\n",
    "\n",
    "#X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forma recomendada de hacer la estandarización es usando **Pipelines**.\n",
    "\n",
    "Los pipelines se pueden usar para encadenar multiples estimadores en uno solo. Son útiles para aplicar una secuencia fija de pasos para procesar los datos. Los pipelines tienen dos propositos:\n",
    "- Simplicidad: Solo hay que llamar a fit o predict una vez y se aplica la secuencia completa de estimadores.\n",
    "- Selección de parámetros conjunta: Con grid search u otro método se podrian buscar todos los parámetros de todos los estimadores a la vez.\n",
    "\n",
    "Todos los estimadores, menos el último deben de ser *transformers* (selectores de atributos, normalización, PCA ...)\n",
    "\n",
    "Un Pipeline se construye usando una lista de (clave, valor) donde la clave contiene el nombre de los que se quiere aplicar y el valor es el objeto del estimador.\n",
    "\n",
    "\n",
    "The Pipeline is built using a list of (key, value) pairs, where the key is a string containing the name you want to give this step and value is an estimator object:\n",
    "\n",
    "```Python\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "estimators = [('reduce_dim', PCA()), ('clf', SVC())]\n",
    "pipe = Pipeline(estimators)\n",
    "pipe \n",
    "```\n",
    "\n",
    "La función **make_pipeline** es una abreviatura para crear pipelines sin tener que dar nombres\n",
    "\n",
    "The utility function make_pipeline is a shorthand for constructing pipelines; it takes a variable number of estimators and returns a pipeline, filling in the names automatically:\n",
    "\n",
    "```Python\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import Binarizer\n",
    "make_pipeline(Binarizer(), MultinomialNB()) \n",
    "```\n",
    "\n",
    "Los estimadores están almacenados como una lista en el atributo **steps** o como un diccionario en el atributo **named_steps** (Esto es importante)\n",
    "\n",
    "Los parámetros del estimador pueden ser accedidos usando la sintaxis <estimator>__<parameter>\n",
    "ejemplo:\n",
    "\n",
    "```Python\n",
    "pipe.set_params(clf__C=10) \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "estimators = [('stantandarize', StandardScaler()), ('clf', MLPClassifier())]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "# entreno el pipe como si fuera un clasificador, \n",
    "# también podría hacer validación cruzada y todo como si fuese un clasificador normal\n",
    "pipe.fit(train, labels)\n",
    "\n",
    "[coef.shape for coef in pipe.named_steps['clf'].coefs_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una función para visualizar la frontera de decisión de un MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_trained_classifier(model, X, y, ax=None, cmap='rainbow'):\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    # Plot the training points\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=cmap,\n",
    "               clim=(y.min(), y.max()), zorder=3)\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    \n",
    "    \n",
    "    # model.fit(X, y)\n",
    "    xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
    "                         np.linspace(*ylim, num=200))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "    # Create a color plot with the results\n",
    "    n_classes = len(np.unique(y))\n",
    "    contours = ax.contourf(xx, yy, Z, alpha=0.3,\n",
    "                           levels=np.arange(n_classes + 1) - 0.5,\n",
    "                           cmap=cmap, clim=(y.min(), y.max()),\n",
    "                           zorder=1)\n",
    "\n",
    "    ax.set(xlim=xlim, ylim=ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una nube de puntos con cuatro clases. Voy a usar estos datos para entrenar un MLP, luego voy a cambiar un poco estos datos y voy a evolucionar los pesos de la red para que se adapten a ese cambio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=300, centers=4,\n",
    "                  random_state=0, cluster_std=1.0)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='rainbow');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(15,), random_state=1)\n",
    "\n",
    "\n",
    "pipe = Pipeline([('stantandarize', StandardScaler()), ('clf', clf)])\n",
    "pipe.fit(X, y)\n",
    "\n",
    "  \n",
    "\n",
    "# model es una copia del pipe que voy a usar en la función de fitness\n",
    "# voy a acceder a la red a traves de su nombre (ver la función MLPFitness)\n",
    "from copy import deepcopy\n",
    "model = deepcopy(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a modificar los pesos obtenidos por backpropagation para que acaben ajustando a Xprima en lugar de a X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xprima=X+[2,1]\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='rainbow');\n",
    "plt.scatter(Xprima[:, 0], Xprima[:, 1], c=y, s=50, cmap='rainbow',alpha=0.2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación las fronteras de decisión con los datos originales y con los datos ligeramente modificados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_trained_classifier(pipe, Xprima, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# accediendo a los pesos de la red a traves de su nombre\n",
    "# model es un pipeline\n",
    "# model.named_steps['clf'] es la red neuronal\n",
    "\n",
    "shapes = [coef.shape for coef in model.named_steps['clf'].coefs_] \n",
    "sizes =[coef.size for coef in model.named_steps['clf'].coefs_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shapes,sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de nada necesito una función para pasar de gen a pesos y otra para pasar de pesos a gen, lógicamente estas funciones necesitan conocer los tamaños y formas de los pesos de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen2Coefs(gen,sizes,shapes):\n",
    "    coefs = []\n",
    "    splits = np.split(gen, [sizes[0]])\n",
    "    for i in range(len(splits)):\n",
    "        coefs.append(splits[i].reshape(shapes[i]))\n",
    "    return coefs\n",
    "\n",
    "def coefs2gen(coefs,sizes,shapes):\n",
    "    return np.concatenate((coefs[0].flatten(),coefs[1].flatten()))\n",
    "\n",
    "'''\n",
    "# Test para probar las funciones anteriores\n",
    "\n",
    "gen = np.arange(sum(sizes))\n",
    "coefs=gen2Coefs(gen,sizes,shapes)\n",
    "print(coefs[0])\n",
    "print(coefs[1])\n",
    "coefs2gen(coefs,sizes,shapes)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función de fitness será el acierto de la red con los pesos del gen, usada para clasificar el conjunto de datos modificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def MLPFitness(individual):\n",
    "    coefs=gen2Coefs(individual,sizes,shapes)\n",
    "    model.named_steps['clf'].coefs_ = coefs  # aqui hay otro cambio\n",
    "    preds = model.predict(Xprima)\n",
    "    acc = accuracy_score(y, preds)\n",
    "    return acc,\n",
    "\n",
    "# Fitness del gen de la red original sobre los datos modificados\n",
    "MLPFitness(coefs2gen(clf.coefs_,sizes,shapes))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Voy a tener una variable que representa el número de veces que voy a meter a la red original en la población inicial.\n",
    "\n",
    "Con N = 0, no meto la red original y todas las redes son aleatorias, ajustando los pesos a los nuevos datos solamente con el genético. Con N=0 llega a un fitness de 0.72\n",
    "\n",
    "Con N = 1, está la red original una vez. Con N=1 llega a un fitness de 0.9\n",
    "\n",
    "Con N = 5, está la red original 5 veces y por lo tanto hay menos individuos aleatorios (llega a 0.92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 5\n",
    "\n",
    "pesosIniciales = coefs2gen(pipe.named_steps['clf'].coefs_,sizes,shapes).copy()\n",
    "\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,)) # Maximiza\n",
    "creator.create(\"Individual\", np.ndarray, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "toolbox.register(\"attr_float\", random.random)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, n=sum(sizes))\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"individual_guess\", lambda :creator.Individual(pesosIniciales))\n",
    "toolbox.register(\"population_mix\",initPopulation,list,toolbox.individual, toolbox.individual_guess)       \n",
    "\n",
    "\n",
    "toolbox.register(\"evaluate\", MLPFitness)\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0.5, sigma=0.5, indpb=0.2)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=10)\n",
    "\n",
    "random.seed(64)\n",
    "# con 50 ya va    \n",
    "population = toolbox.population_mix(n=50, n_guess=N)  \n",
    "\n",
    "    \n",
    "hof = tools.HallOfFame(1, similar=np.array_equal)\n",
    "    \n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"std\", np.std)\n",
    "stats.register(\"min\", np.min)\n",
    "stats.register(\"max\", np.max)\n",
    "    \n",
    "population, logbook = algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=50, stats=stats, halloffame=hof)\n",
    "#print(hof) # hall of the fame contiene el mejor individuo vivo en cada generacion\n",
    "mejorInd = hof[0] # esta ordenado de manera que el primer elemento es el mejor de siempre\n",
    "\n",
    "MLPFitness(mejorInd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# frontera de decisión del mejor individuo de la población\n",
    "\n",
    "model.coefs_= gen2Coefs(mejorInd,sizes,shapes) \n",
    "visualize_trained_classifier(model, Xprima, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# frontera de decisión original\n",
    "visualize_trained_classifier(pipe, Xprima, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
